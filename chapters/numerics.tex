In line with a thesis in computational astrophysics, the equations of motion presented here do not admit closed-form analytical solutions. As such, we must rely on numerical methods and computer simulations to solve them. Specifically, I solve $N$ independent sets of Hamilton's equations, each consisting of six first-order, coupled differential equations.

Numerical integration presents several challenges. First, there is the practical question: how do we actually solve these equations? Most students first encounter a simple update scheme, such as Euler's method: $y_{i+1} = y_i + \frac{dy}{dt}\Delta t$. However, this quickly becomes insufficient for coupled systems or for problems where precision and conservation laws are essential. How can we be confident that our numerical solutions faithfully approximate the true dynamics, especially when the true solution is unknown? How do we handle performance, data volume, or the trade-offs between speed and accuracy?

Although many software packages already exist to solve such problems, I chose to write my own code. Some senior researchers warn, ``Don't reinvent the wheel.'' Others lamet that ``the problem with the youth today is that no one knows how the packages they use work.'' Caught between damned if I do and damned if I don't, I decided to write my own solver anyway. This led to the development of \texttt{tstrippy}, a code designed to solve the restricted three-body problem. My motivation was part practical: I wanted to avoid installation headaches, steep learning curves, and uncertainty over whether existing tools could handle my specific setup. But above all else, I wanted to create a reliable product that works, allows me to reproduce my results, and run my simulations at scale. 

Developing my own package gave me a deeper understanding of code structure, numerical algorithms, and the subtleties of scientific programming. It also gave me the confidence to later use other packages more effectively. The \texttt{tstrippy} code is available on GitHub and runs on macOS and Linux.

This chapter documents how I numerically solve the equations of motion, how I validate the accuracy of the solutions, and how the code is organized under the hood.



\section{Astronomical units}

    When writing any code, the choice of units is important. Astronomical units are rarely the same as SI units. In general, the choice of units is observationally and historically motivated, which results in a system that uses multiple units for the same quantity, which can be confusing at first. 
    
    For instance, sky positions are typically reported in spherical coordinates. Right ascension (analogous to longitude) is often expressed in either degrees or hours, while declination (similar to latitude) is given in degrees. Distances are reported in partsecs when derived from parallax measurements. Line-of-sight velocities, obtained via spectrospoic Doppler shifts, are reported in kilometers per second. Proper motions describe angular displacement over time, usually reported in miliarcseconds per yera. Already, we encounter several different units for angles (degrees, hours, arcseconds), times (years, seconds), and distance (km, kpc), none of which align with the SI's radians, seconds, or meters, as summarized in Table~\ref{tab:units}.

    \begin{table}[]
        \caption{Units for various astronomical quantities in Galactic and SI systems.}
        \label{tab:units}
        \begin{tabular}{l|l|l|l|l|l|l|}
                            & Distance  & RA                     & DEC                    & \textbf{$\mathrm{v}_\mathrm{LOS}$} & $\mu_\alpha$ & $\mu_\delta$ \\ \hline
            Galactic: & {[}kpc{]} & {[}deg{]} {[}HHMMSS{]} & {[}deg{]}  & km/s                      & {[}mas/yr{]} & {[}mas/yr{]} \\ \hline
            S.I.       & {[}m{]}   & {[}rad{]}              & {[}rad{]}              & m/s                       & {[}rad/s{]}  & {[}rad/s{]}  \\ 
        \end{tabular}
    \end{table}

    This raises practical concerns, for example, what would be the unit of acceleration? km/s$^2$? parsec/year/second? To systematically manage units, we turn to dimesnional anslysis, notably the Buckingham Pi theorem. In classical mechanics, phyiscal quantities are typically expressed in terms of three fundamental dimesnions: length, time, and mass. Any quantity can then be represented as a product of powers of these base units: 

    \begin{equation}
        \left[\mathrm{Quantity}\right] = \mathcal{l}^a t^b m^c =
            \begin{bmatrix}
                a\\
                b\\
                c 
            \end{bmatrix}
    \end{equation}
    For example, velocity has dimesnions: $\left[1, -1, 0\right]$, momentum is $[1,-1,1]$, and acceleration is $[1,-2,0]$. 

    It is not strictly necessary to adopt length-time-mass as the fundamental basis, as long as the three choosen base units are linearly independent. In stellar dynamics, it is often more natural to use distance, velocity, and mass as the fundamental units. In this thesis, I adopt:
    \begin{itemize}
        \item Distance: 1~kpc
        \item Velocity: 1 km/s 
        \item Mass: 1 solar mass $\mathrm{M}_\odot$
    \end{itemize}

    In this system, time as derived units of: 

    \begin{equation}
        \left[t\right] = \frac{\mathrm{distance}}{\mathrm{velocity}} = \frac{\mathrm{kpc}}{\mathrm{km/s}},
    \end{equation}
    While not immediately intuitive, this unit of time is convenient becuase: 
    \begin{equation}
        1\frac{\mathrm{kpc}}{\mathrm{Gyr}} \approx 1\frac{\mathrm{km}}{\mathrm{s}}.
    \end{equation}

    The gravitational constant has dimensions of:
    \begin{equation}    
        \left[G\right]=\frac{v^2 \cdot l}{m}
    \end{equation} 
    which evaluates numerically in these units as: 
    
    \begin{equation}
        G = 4.301 \times 10^{-6} \left(\mathrm{km}/\mathrm{s}\right)^2 \cdot \mathrm{kpc} \cdot \mathrm{M}_\odot^{-1}.
    \end{equation}
    Once the base units are defined, derived quantities such as acceleration follow directly. One finds that considering acceleration as $v^2~l^{-1}$ or $l\cdot t^{-2}$, they are equivalent and: $\left(\mathrm{kpc}/\mathrm{s}\right)^2 \cdot \mathrm{kpc}^{-1}$. 

    It is worth mentioning that $N$-body codes often simplify further by selecting the distance, velocity, and the gravitational constant as the base units, setting $G=1$. While this simplifies force computations, it introduces less intuitive units for mass. For instance, by choosing 1~kpc for distance and 1~km/s for velocity, and setting $G=1$, the derived mass unit becomes: 
    \begin{equation}
        \left[\mathrm{mass}\right] = \frac{l \cdot v^2}{G} = 232509~\mathrm{M}_\odot
    \end{equation}

    This approach was used in our first paper (see chapter 4). Another example is the case of \texttt{Galpy}. \citet{2015ApJS..216...29B} introduced \textit{natural units} which is motivated by the rotation curve of a galaxy and is embodied through: 
    \begin{equation}
        \frac{v_\mathrm{circ}^2}{R} = \nabla  \Phi \left(R, z=0\right)
        \label{eq:vcirc}
    \end{equation}
    which is the circular velocity for a system with cylindrical symmetry evaluated in the plane. In this normalization, $R$ is the cylindrical scale length of the galaxy and $v_\mathrm{circ}$ is the circular velocity at this radius evaluated in the plane, both of which are set to 1, and the gravitational constant is set to 1. Whatever the form of the potential, the scale lengths must be normalized to $R$, and subsequently the the Mass parameter is determined through Eq.~\ref{eq:vcirc}. The total potential is a linear combination of the individual components and the user chooses how much each contributes to the force at the characteristic radius. For instance, $\Phi = \sum_i a_i\Phi_i$, where $a_i$ are the weights of each component $\Phi_i$, such that $\nabla \Phi_i(R,z=0) = a_i$ in normalized units. In this choice of units, the emphasis is placed on the rotation curve and how much each component contributes to it at the characteristic radius of the system. Note that the $v_\mathrm{circ}(R_o)$ is not necessarily the maximum value. 

    In short, each code presents its best units and normalization. It is the job of a computational astrophysicist to understand how these units work and be able to transform to observable quantities and physical units. $N$-body codes work in best when picking $G=1$, and \texttt{Galpy} presents natrual units which is best when the focus is on over all characteristic of the rotation curve for a galaxy. \texttt{Tstrippy} expects the user to pass masses in solar masses, velocities in kilometers per second, and distances in kpc. I choose this for I believe it is the most intuitive on the user end and matches the way values are typically reported for galaxies. 
    


    
    

\section{Tstrippy}

    \citet{2018ComAC...5....2V} talks about a series of papers between a larger collaboration of people who specialize in collisional dynamics and who have performed a series of workshops together. The introduction stated that the collaboration wants to tackle many open questions regarding stellar clusters and build the necessary codes to interprete the future large quantity of data that was destined to come. It has now come since the review was 2018. An interesting point was that in general globular clusters are approximated as being orderless, i.e. isotropic but order does present itself within these stelalr systems. Another large problem is no one knows what a good set of initial conditiosn is. Unresolved binaries pose a problem because you can overestiamte the total mass of the system. If I talk about this review, I should probably discuss some of the results from the papers that is builds on or at least their techinques.

    The MODEST review led me to discover AMUSE, which is an framework for integrating various astrophysical codes for solving 4 types of problems: gravitational dynamics, radiative transfer, hydrodynamics, and stellar evolution. The codes are written by the community and are interfaced together with Amuse. The user end is python. I have spent some time reading the book, which is instructive and well written. Steve McMillian is one of the authors. The code has a large support on GitHub and is still being developped. I have had trouble trying to install the code. It seems as though their documentation is incoherrent. At one place, it said `pip' is the easiest way to install. It didn't work. In another place, I was instructed to install a zipped up tarball. The setup failed becuase it expected there to be a .git file in the directory. I successfully downloaded the code by cloneing the repository, despite the fact that this was not recommended. I can use some aspects of the code but not all of them. For instance, my memory tells me that about 80\% of the test suite passed, thus many scripts failed. This was when I only installed the frame-work, which was advised since installing the whole package is huge and unnecessary since I am not solving all astrophysical problems. However, I wasn't able to use one of the gravity solvers that was presented in the textbook `AstrophysicalRecipes The art of AMUSE'. The install still has some codes that failed for instance: amuse-adaptb, amuse-hermite-grx, amuse-mi6. However, I'm hoping that this isn't necessary. I want to educate myself and make some examples. 

    Installing other codes and figuring out their functionalities to me has never been trivial. This is similar to galpy when I tried to figure out particle spray method and got less than good results. Agama also confused me a bit. The main point is that for each package, at the end of the day I decided that it was easier and better if I solved the problem myself with my own code. Because, even with the other packages, I know that they can be used to solve other astrophysical problems and it wasn't clear to me how to make the codes solve my specific set of of the restricted three body problems in a potential with other perturbers flying around. 

    In this search, I also discovered another review called \textit{Computational methods for collisional stellar systems} by Spurzem and Kamlah 2023. It is also interesting and instructive. I found it insightful when they called NBody an industry. I think the story of GRAPE and Makino is really interesting, how he build dedicated hardware for the nbody problem which were great for 10 years but were quickly replaced by GPU technology. 
    \begin{itemize}
        \item f2py, and why did we choose to use Fortran? 
        \item Bovy's guide for making a public python package
        \item migrating going from setuptools to meson
        \item a brief overview of how it works. 
        \item how I can either save orbits or snapshots
    \end{itemize}



\section{Numerical Errors and Schema} 

    If we consider the following differential equation, $\frac{dy}{dt}=m$, whose general solution is: $y=mt+b$. If we are working double-precision numbers who use 64-bits to represent real numbers, then the general solution is only 16 bytes. However, if we use newton's method to find a particular solution given an initial condition $b$, then we must evaluate $t_i,y_i$ at each time step considered. The data volume becomes $2\times N_\mathrm{steps}\times 8 \mathrm{bytes}$. 

    With numerical solutions in general, we have a set of initial conditions, and evaluting Hamilton's equations at them provides the instantaneous evolution of the system. If we use a sufficiently small time step, we can then find the next state of the system. \textit{Sufficiently small} means that the numerical solution converges to the \textit{true solution} and only differs by accumulated numerical error from machine precision. 

    \begin{verbatim}
    VIDEO: cluster_showing_scale_and_dynamical_time.mp4
    \end{verbatim}
    Display here some results where I tried to use the higher order leap frog... i.e. the Ruth method. 

    Make a qualitative argument against the 

    \begin{itemize}
        \item leapfrog is sympletic, preserve hamiltonian in the transform
        \item integrating at high resolution, downsampling for storage, and then interpolating if higher resolution is needed. 
        \item I tried to implement the Ruth-Ford
        \item I tried to implement the king model, which was slower and worse and not worth it 
    \end{itemize}


    \section{Computation time and Data Volume}
    \begin{itemize}
        \item there are practical restraints
        \item we choose to solve the restricted three body problem b/c
    \end{itemize}

\section{My work flow}
    \begin{itemize}
        \item Tstrippy is the production code
        \item then I have gcs which does data i/o
        \item then I have an analysis package that makes plots based on the final data products
    \end{itemize}

