As in line with a thesis on computational astrophysics, the equations of motion presented in this thesis do not have closed for analytical solutions and thus we must turn to computers to solve them. Here, I am solving N-independent sets of Hamilton's equations, in which each set contains 6 first order coupled differential equations. Solving equations numerically introduces a series of problems that must be delt with. First, practically, how do we solve them? We are all familiar with newton's method how finds the time-evolution of a function with the derivative: $y_{i+1} = \frac{dy}{dt}\Delta t + y_i$. But what about coupled equations? How can we ensure ourselves that the numerical solution well approximates the true solution, if we don't know the true solution? What about data volume, efficieny? 

Consider the following example. If we consider the following differential equation, $\frac{dy}{dt}=m$, whose general solution is: $y=mt+b$. Consider the data volume. If we are working double-precision numbers who use 64-bits to represent real numbers, then the general solution is only 16 bytes. However, if we use newton's method to find a particular solution given an initial condition $b$, then we must evaluate $t_i,y_i$ at each time step considered. The data volume becomes $2\times N_\mathrm{steps}\times 8 \mathrm{bytes}$. 

With numerical solutions in general, we have a set of initial conditions, and evaluting Hamilton's equations at them provides the instantaneous evolution of the system. If we use a sufficiently small time step, we can then find the next state of the system. \textit{Sufficiently small} means that the numerical solution converges to the \textit{true solution} and only differs by accumulated numerical error from machine precision. 


\section{Astronomical units and scaling}

    Astronomical units are weird: 

    \begin{table}[]
        \caption{Units for various astronomical quantities in Galactic and SI systems.}
        \label{tab:units}
        \begin{tabular}{l|l|l|l|l|l|l|}
                            & Distance  & RA                     & DEC                    & \textbf{$\mathrm{v}_\mathrm{LOS}$} & $\mu_\alpha$ & $\mu_\delta$ \\ \hline
            Galactic: & {[}kpc{]} & {[}deg{]} {[}HHMMSS{]} & {[}deg{]} {[}HHMMSS{]} & km/s                      & {[}mas/yr{]} & {[}mas/yr{]} \\ \hline
            S.I.       & {[}m{]}   & {[}rad{]}              & {[}rad{]}              & m/s                       & {[}rad/s{]}  & {[}rad/s{]}  \\ 
        \end{tabular}
    \end{table}


\section{Tstrippy}

    \citet{2018ComAC...5....2V} talks about a series of papers between a larger collaboration of people who specialize in collisional dynamics and who have performed a series of workshops together. The introduction stated that the collaboration wants to tackle many open questions regarding stellar clusters and build the necessary codes to interprete the future large quantity of data that was destined to come. It has now come since the review was 2018. An interesting point was that in general globular clusters are approximated as being orderless, i.e. isotropic but order does present itself within these stelalr systems. Another large problem is no one knows what a good set of initial conditiosn is. Unresolved binaries pose a problem because you can overestiamte the total mass of the system. If I talk about this review, I should probably discuss some of the results from the papers that is builds on or at least their techinques.

    The MODEST review led me to discover AMUSE, which is an framework for integrating various astrophysical codes for solving 4 types of problems: gravitational dynamics, radiative transfer, hydrodynamics, and stellar evolution. The codes are written by the community and are interfaced together with Amuse. The user end is python. I have spent some time reading the book, which is instructive and well written. Steve McMillian is one of the authors. The code has a large support on GitHub and is still being developped. I have had trouble trying to install the code. It seems as though their documentation is incoherrent. At one place, it said `pip' is the easiest way to install. It didn't work. In another place, I was instructed to install a zipped up tarball. The setup failed becuase it expected there to be a .git file in the directory. I successfully downloaded the code by cloneing the repository, despite the fact that this was not recommended. I can use some aspects of the code but not all of them. For instance, my memory tells me that about 80\% of the test suite passed, thus many scripts failed. This was when I only installed the frame-work, which was advised since installing the whole package is huge and unnecessary since I am not solving all astrophysical problems. However, I wasn't able to use one of the gravity solvers that was presented in the textbook `AstrophysicalRecipes The art of AMUSE'. The install still has some codes that failed for instance: amuse-adaptb, amuse-hermite-grx, amuse-mi6. However, I'm hoping that this isn't necessary. I want to educate myself and make some examples. 

    Installing other codes and figuring out their functionalities to me has never been trivial. This is similar to galpy when I tried to figure out particle spray method and got less than good results. Agama also confused me a bit. The main point is that for each package, at the end of the day I decided that it was easier and better if I solved the problem myself with my own code. Because, even with the other packages, I know that they can be used to solve other astrophysical problems and it wasn't clear to me how to make the codes solve my specific set of of the restricted three body problems in a potential with other perturbers flying around. 

    In this search, I also discovered another review called \textit{Computational methods for collisional stellar systems} by Spurzem and Kamlah 2023. It is also interesting and instructive. I found it insightful when they called NBody an industry. I think the story of GRAPE and Makino is really interesting, how he build dedicated hardware for the nbody problem which were great for 10 years but were quickly replaced by GPU technology. 
    \begin{itemize}
        \item f2py, and why did we choose to use Fortran? 
        \item Bovy's guide for making a public python package
        \item migrating going from setuptools to meson
        \item a brief overview of how it works. 
        \item how I can either save orbits or snapshots
    \end{itemize}



\section{Numerical Errors and Schema} 

    \begin{verbatim}
    VIDEO: cluster_showing_scale_and_dynamical_time.mp4
    \end{verbatim}
    Display here some results where I tried to use the higher order leap frog... i.e. the Ruth method. 

    Make a qualitative argument against the 

    \begin{itemize}
        \item leapfrog is sympletic, preserve hamiltonian in the transform
        \item integrating at high resolution, downsampling for storage, and then interpolating if higher resolution is needed. 
        \item I tried to implement the Ruth-Ford
        \item I tried to implement the king model, which was slower and worse and not worth it 
    \end{itemize}


    \section{Computation time and Data Volume}
    \begin{itemize}
        \item there are practical restraints
        \item we choose to solve the restricted three body problem b/c
    \end{itemize}

\section{My work flow}
    \begin{itemize}
        \item Tstrippy is the production code
        \item then I have gcs which does data i/o
        \item then I have an analysis package that makes plots based on the final data products
    \end{itemize}

