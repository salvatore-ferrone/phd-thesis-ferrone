In line with a thesis in computational astrophysics, the equations of motion presented here do not admit closed-form analytical solutions. As such, we must rely on numerical methods and computer simulations to solve them. Specifically, I solve $N$ independent sets of Hamilton's equations, each consisting of six first-order, coupled differential equations.

Numerical integration presents several challenges. First, there is the practical question: how do we actually solve these equations? Most students first encounter a simple update scheme, such as Euler's method: $y_{i+1} = y_i + \frac{dy}{dt}\Delta t$. However, this quickly becomes insufficient for coupled systems or for problems where precision and conservation laws are essential. How can we be confident that our numerical solutions faithfully approximate the true dynamics, especially when the true solution is unknown? How do we handle performance, data volume, or the trade-offs between speed and accuracy?

Although many software packages already exist to solve such problems, I chose to write my own code. Some senior researchers warn, ``Don't reinvent the wheel.'' Others lamet that ``the problem with the youth today is that no one knows how the packages they use work.'' Caught between damned if I do and damned if I don't, I decided to write my own solver anyway. This led to the development of \texttt{tstrippy}, a code designed to solve the restricted three-body problem. My motivation was part practical: I wanted to avoid installation headaches, steep learning curves, and uncertainty over whether existing tools could handle my specific setup. But above all else, I wanted to create a reliable product that works, allows me to reproduce my results, and run my simulations at scale. 

Developing my own package gave me a deeper understanding of code structure, numerical algorithms, and the subtleties of scientific programming. It also gave me the confidence to later use other packages more effectively. The \texttt{tstrippy} code is available on GitHub and runs on macOS and Linux.

This chapter documents how I numerically solve the equations of motion, how I validate the accuracy of the solutions, and how the code is organized under the hood.



\section{Astronomical units and scaling}

    When writing any code, the choice of units is important. Astronomical units are rarely the same as SI units. In general, the choice of units is observationally and historically motivated, resulting in a system that uses multiple units for the same physical quantity, which can be confusing at first.

    For instance, sky positions are typically reported in spherical coordinates. Right ascension (analogous to longitude) is often expressed in either degrees or hours, while declination (similar to latitude) is given in degrees. Distances are reported in parsecs when derived from parallax measurements. Line-of-sight velocities, obtained via spectroscopic Doppler shifts, are reported in kilometers per second. Proper motions describe angular displacements over time and are usually reported in milliarcseconds per year. Already, we encounter several different units for angles (degrees, hours, arcseconds), time (years, seconds), and distance (km, kpc), none of which align with SI’s standard units of radians, seconds, or meters, as summarized in Table~\ref{tab:units}.

    \begin{table}[]
        \caption{Units for various astronomical quantities in Galactic and SI systems.}
        \label{tab:units}
        \begin{tabular}{l|l|l|l|l|l|l|}
                            & Distance  & RA                     & DEC                    & \textbf{$\mathrm{v}_\mathrm{LOS}$} & $\mu_\alpha$ & $\mu_\delta$ \\ \hline
            Galactic: & {[}kpc{]} & {[}deg{]} {[}HHMMSS{]} & {[}deg{]}              & km/s                      & {[}mas/yr{]} & {[}mas/yr{]} \\ \hline
            S.I.       & {[}m{]}   & {[}rad{]}              & {[}rad{]}              & m/s                       & {[}rad/s{]}  & {[}rad/s{]}  \\ 
        \end{tabular}
    \end{table}

    This raises practical concerns—for example, what would be the unit of acceleration? km/s$^2$? parsec/year/second? To systematically manage units, we turn to dimensional analysis, notably the Buckingham Pi theorem. In classical mechanics, physical quantities are typically expressed in terms of three fundamental dimensions: length, time, and mass. Any quantity can then be represented as a product of powers of these base units:

    \begin{equation}
        \left[\mathrm{Quantity}\right] = \mathcal{l}^a t^b m^c =
            \begin{bmatrix}
                a\\
                b\\
                c 
            \end{bmatrix}
    \end{equation}

    For example, velocity has dimensions $[1, -1, 0]$, momentum is $[1, -1, 1]$, and acceleration is $[1, -2, 0]$.

    It is not strictly necessary to adopt length-time-mass as the fundamental basis, as long as the three chosen base units are linearly independent. In stellar dynamics, it is often more natural to use distance, velocity, and mass as the base units. In this thesis, I adopt:
    \begin{itemize}
        \item Distance: 1~kpc
        \item Velocity: 1~km/s 
        \item Mass: 1~solar mass $\mathrm{M}_\odot$
    \end{itemize}

    In this system, time has derived units of:
    \begin{equation}
        \left[t\right] = \frac{\mathrm{distance}}{\mathrm{velocity}} = \frac{\mathrm{kpc}}{\mathrm{km/s}}.
    \end{equation}
    While not immediately intuitive, this unit of time is convenient because:
    \begin{equation}
        1\frac{\mathrm{kpc}}{\mathrm{Gyr}} \approx 1\frac{\mathrm{km}}{\mathrm{s}}.
    \end{equation}

    The gravitational constant has dimensions:
    \begin{equation}    
        \left[G\right]=\frac{v^2 \cdot l}{m},
    \end{equation} 
    which evaluates numerically in these units as: 
    \begin{equation}
        G = 4.301 \times 10^{-6} \left(\mathrm{km}/\mathrm{s}\right)^2 \cdot \mathrm{kpc} \cdot \mathrm{M}_\odot^{-1}.
    \end{equation}

    Once the base units are defined, derived quantities such as acceleration follow directly. Whether considering acceleration as $v^2~l^{-1}$ or $l \cdot t^{-2}$, they are equivalent and yield: $\left(\mathrm{kpc}/\mathrm{s}\right)^2 \cdot \mathrm{kpc}^{-1}$.

    It is worth mentioning that $N$-body codes often simplify further by selecting distance, velocity, and the gravitational constant as the base units, setting $G = 1$. While this simplifies force computations, it introduces less intuitive units for mass. For instance, by choosing 1~kpc for distance and 1~km/s for velocity, and setting $G = 1$, the derived mass unit becomes:
    \begin{equation}
        \left[\mathrm{mass}\right] = \frac{l \cdot v^2}{G} = 232509~\mathrm{M}_\odot.
    \end{equation}

    This approach was used in our first paper (see Chapter~4). Another example is the case of \texttt{Galpy}. \citet{2015ApJS..216...29B} introduced \textit{natural units} motivated by the galaxy's rotation curve, embodied in:
    \begin{equation}
        \frac{v_\mathrm{circ}^2}{R_0} = \nabla  \Phi \left(R_0, z=0\right),
        \label{eq:vcirc}
    \end{equation}
    which is the circular velocity in a cylindrically symmetric potential evaluated in the plane. In this normalization, $R$ is the cylindrical scale length of the galaxy, and $v_\mathrm{circ}$ is the circular velocity at this radius, both of which are set to 1. The gravitational constant is also set to 1. Whatever the form of the potential, the scale lengths must be normalized to $R$, and the mass parameter is subsequently determined through Eq.~\ref{eq:vcirc}. The total potential is a linear combination of individual components, with the user selecting the contribution of each component to the force at the characteristic radius. For example, $\Phi = \sum_i a_i\Phi_i$, where $a_i$ are weights such that $\nabla \Phi_i(R_0, z=0) = a_i$ in normalized units.

    In this system of units, emphasis is placed on the rotation curve and how much each component contributes to it at the reference radius of the galaxy. Note that $v_\mathrm{circ}(R_0)$ is not necessarily the maximum value of the rotation curve.

    In short, each code presents its own preferred units and normalization. It is the job of a computational astrophysicist to understand these conventions and be able to convert between them and observable quantities. $N$-body codes work best when setting $G = 1$, while \texttt{Galpy} uses natural units that emphasize the rotational properties of a galaxy. \texttt{Tstrippy}, by contrast, expects the user to pass masses in solar masses, velocities in kilometers per second, and distances in kiloparsecs.  However, physical constants are not hard-coded, so the user may pass any numerical values to the code as long as they are based on a self-consistent unit system. The code includes the \texttt{Pouliasis2017pii} potential and a catalog of galactic globular cluster properties, both reported in the aforementioned units.

    A valid general strategy when developing numerical codes is to implement a module that converts user-defined units to the internal units of the code. This functionality also exists in \texttt{Galpy} and a similar system is implemented in \texttt{Agama} \citep{2018arXiv180208255V}. I chose not to add such a layer to \texttt{Tstrippy}, since my goal was not to develop the most robust tool in the field, but rather to answer specific scientific questions. That said, \texttt{Astropy} provides an excellent unit-handling module that allows users to convert between units easily \citep{2013A&A...558A..33A}, and I recommend its use in the documentation. 

    In the end, I chose this unit convention because I believe it is the most intuitive for users and aligns with how quantities are typically reported in galactic astronomy.


\section{Solving the equations of motion}

    Long before the advent of computers, Euler proposed a simple method for numerically solving differential equations. However, it is inefficient and inaccurate for coupled systems, especially when long-term behavior matters. In the case of Hamiltonian systems, we can exploit specific geometric properties to design numerical schemes that better preserve the qualitative features of the true solution.

    In this thesis, I implemented the Leapfrog integrator and the Forest-Ruth scheme. These schemes are derived from the structure of Hamiltonian mechanics and are known as \textit{symplectic integrators}. Before continuing, I would like to quote \citep{bovy_inprep}:

    \begin{quote}
        Hamiltonian integrators are often called symplectic. This name comes from the fact that these integrators are Hamiltonian maps, whose mathematical structure is that of a vector flow on a symplectic manifold. Many fine dynamicists have made great contributions to the field without delving deeply into the meaning of the previous sentence and we do not discuss this further.
    \end{quote}

    However, my curiosity about linguistics pushed me to delve further: What does \textit{symplectic} mean? \citet{weyl1946classical} coined the term because \textit{complex} was already taken. The prefix \textit{com} refers to together, and ``plexus'' comes from greek meaning ``woven'' or ``braided''. So from its roots, “complex” means something composed of interwoven parts. The image of tangled braids captures the idea well. Similarly, ``sym-'' is a Greek prefix meaning “together.” The idea remains the same: in Hamiltonian dynamics, the evolution of position and momentum are interdependent. This becomes clearer in matrix form:
    \begin{equation}
        \begin{bmatrix}
            \dot{\bf{q}}\\
            \dot{\bf{p}}
        \end{bmatrix}
         = 
        \begin{bmatrix}
            0 & I_n \\
            -I_n & 0 
        \end{bmatrix}
                \begin{bmatrix}
            \frac{\partial \mathcal{H}}{\partial \bf{q}} \\
            \frac{\partial \mathcal{H}}{\partial \bf{p}}
        \end{bmatrix}
        \label{eq:symplectic}
    \end{equation}
    Here, the skew-symmetric matrix “weaves” the positions and momenta together.

    Although the equations of motion do not admit analytical solutions, they possess several known properties. First, trajectories governed solely by gravity are time-reversible. This property is important for my methodology, where I integrate the equations of motion backward in time and then forward again to the present-day position. Secondly, the total orbital energy is conserved. Moreover, according to Liouville's theorem, Hamiltonian flows preserve the local phase space volume. A corollary of this is that the determinant of the Jacobian matrix of the transformation from $\left(q,p\right)\rightarrow \left(q',p'\right)$ must be one, which means that the transformation only rotates or translates an infinitesimal volume but does not shrink or expand the volume. We can view the transform as: 
    \begin{eqnarray}
        q' &= q + \frac{\partial \mathcal{H}}{\partial p}\Delta t, \\
        p' &= -\frac{\partial \mathcal{H}}{\partial q}\Delta t + p,
    \end{eqnarray}
    The Jacobian matrix is given by $\left(\frac{\partial x_i'}{\partial x_j }\right)$: 
    \begin{equation}
        \begin{bmatrix}
            1 & \Delta t \frac{\partial^2 \mathcal{H}}{\partial p^2} \\  
            -\Delta t \frac{\partial^2 \mathcal{H}}{\partial q^2} & 1 \\  
        \end{bmatrix}
    \end{equation}
    and the subsequent determinant is: 
    \begin{equation}
        \mathrm{det}\left(J\right) = 1 - \Delta t^2 \frac{\partial^2 \mathcal{H}}{\partial q^2} \frac{\partial^2 \mathcal{H}}{\partial p^2}.
    \end{equation}
    In general, neither $\frac{\partial^2 \mathcal{H}}{\partial q^2}$ or $\frac{\partial^2 \mathcal{H}}{\partial p^2}$ are zero. Therefore, to preserve phase-space volume, we update positions and momenta in alternating steps. The transformation order becomes: $(q,p) \rightarrow (q',p) \rightarrow (q',p')$. This is commonly referred to as a sequence of \textit{drifts} and \textit{kicks}. A \textit{drift} updates the position while holding the momentum fixed, and a \textit{kick} updates the momentum while holding the position fixed. Symplectic integrators alternate these operations in a specific sequence to preserve the structure of Hamiltonian flow.

    The scheme outlined above is essentially a first-order method and is closely related to Euler's method. More sophisticated integrators use values from multiple time steps to construct higher-order estimates of the system's evolution. For example, some schemes temporarily evolve the position to an intermediate value $q_\mathrm{temp}$, use this to compute a momentum $p_\mathrm{temp}$, and then adjust both using weighted averages or predictor-corrector steps to reach the final state. These methods carefully balance forward and backward steps to optimize accuracy while preserving the symplectic structure.

    One of the most commonly used integrators in galactic dynamics is the leapfrog method. It works by interleaving updates of positions and momenta using time-centered averages. Specifically, the average momentum between $q_i$ and $q_{i+1}$ (denoted $p_{i+1/2}$) is used to advance the position, and then the average force (derived from the potential) is used to update the momentum. In Cartesian coordinates—used throughout this thesis—the leapfrog algorithm can be rewritten in terms of grid-aligned quantities:


    \begin{eqnarray}
        x_{i+1} &= x_i + \dot{x}_i \Delta t + \frac{1}{2}\ddot{x}_i \Delta t^2, \\
        \ddot{x}_{i+1} &= -\nabla \Phi(x_{i+1}), \\
        \dot{x}_{i+1} &= \dot{x}_i + \frac{1}{2}\left(\ddot{x}_i + \ddot{x}_{i+1}\right)\Delta t.
    \end{eqnarray}
    This formulation highlights how the leapfrog method naturally incorporates the second-order accuracy and time-reversibility essential for modeling gravitational systems over long timescales. As I will show in the next section, the leapfrog algorithm is sufficient for the problems that I solve. However, the question of computational efficiency and numerical accuracy is ever present. Leapfrog uses uses the two local points about the position and momenta to evolve them. Other schema can use more points to have more accurate estimations for the local derivatives. 
    
    \citet{1990PhyD...43..105F} proposed one such method for symplectic integrations, which is our situation here. The method is complicated and involves finding roots of high order polynomials, and the roots of which determine the weights and distances about the local point for finding the best estimate of the derivative for evoling the system. The method involves solving a cubic polynomial to determine the optimal coefficients. While the derivation is mathematically involved, the final scheme is straightforward to implement. Nonetheless, I implemented this method and tested its efficiency against the leapfrog. There are eight coefficients in this method, which are presented in table~\ref{tab:forest_ruth_coeffs}.
    \begin{table}[h]
        \centering
        \caption{Velocity (\(c_n\)) and acceleration (\(d_n\)) coefficients for the Forest-Ruth symplectic integrator.}
        \label{tab:forest_ruth_coeffs}
        \begin{tabular}{ccccc|cccc}
            \multicolumn{4}{c|}{Velocity coefficients (\(c_n\))} & \multicolumn{4}{c}{Acceleration coefficients (\(d_n\))} \\
            $c_1$ & $c_2$ & $c_3$ & $c_4$ & $d_1$ & $d_2$ & $d_3$ & $d_4$ \\
            \hline
            $w + \frac{1}{2}$ & $-w$ & $-w$ & $w + \frac{1}{2}$ & $2w + 1$ & $-4w - 1$ & $2w + 1$ & $0$ \\
        \end{tabular}
    \end{table} 
    The coefficients are all based on the solution to the cubic polynomial: $48 w^3 + 24 w^2 - 1 = 0 $. For a single step, the positions and velocities are updated as follows:
    \begin{align} 
        x' &= x + c_n v \Delta t \\ 
        t' &= t + c_n \Delta t \\ 
        \ddot{x} &= \nabla \Phi (x') \\ 
        \dot{x}' &= \dot{x} + d_n \ddot{x} \Delta t,
    \end{align}
    where $n$ is the \textit{mini-step}. Notice that the sum of $\sum_n^4 c_n$ and $\sum_n^4 d_n$ both equal 1, which is a full time step $\Delta t$. 

    Lastly, it is important to note that the leapfrog algorithm is symplectic and time-reversible only for Hamiltonians that are both time-independent and separable—that is, where the Hamiltonian can be written as a sum of a kinetic term depending only on momenta, $T(p)$ and whose potential depends only on position $\Phi(q)$. These conditions are satisfied for systems in an inertial frame with conservative forces. This is true when I integrate the motion for the center of mass of the globular clusters. However, the Hamiltonian for the integration of the particles does depend on time. So the leapfrog algorithm may introduce systematic integration errors due to the violation of its underlying assumptions, beyond ordinary rounding errors.

    Similarly, when we integrate the orbits of either the particles or the globular clusters in the galaxy containing a galactic bar, we are faced with a choice: we can either work in a time-dependent inertial frame, where the potential rotates and the Hamiltonian explicitly depends on time, or we can transform to a rotating frame, in which case the kinetic energy becomes position-dependent due to Coriolis and centrifugal forces, which breaks the necessary criteron of separability: $\mathcal{H}(q,p) = T(p)+\Phi(q)$. In both cases, the standard assumptions of the leapfrog algorithm are violated.

    Nonetheless, we will continue to use leapfrog as it remains a robust and efficient integrator for a wide range of astrophysical systems. Its good long-term energy behavior makes it a reasonable approximation even when the ideal assumptions are not strictly met. However, this highlights the need for careful validation: we must verify that the integration errors remain within acceptable bounds, especially in systems with non-separable or time-dependent dynamics. This validation is the subject of the next section.







\section{Tstrippy}

    \citet{2018ComAC...5....2V} talks about a series of papers between a larger collaboration of people who specialize in collisional dynamics and who have performed a series of workshops together. The introduction stated that the collaboration wants to tackle many open questions regarding stellar clusters and build the necessary codes to interprete the future large quantity of data that was destined to come. It has now come since the review was 2018. An interesting point was that in general globular clusters are approximated as being orderless, i.e. isotropic but order does present itself within these stelalr systems. Another large problem is no one knows what a good set of initial conditiosn is. Unresolved binaries pose a problem because you can overestiamte the total mass of the system. If I talk about this review, I should probably discuss some of the results from the papers that is builds on or at least their techinques.

    The MODEST review led me to discover AMUSE, which is an framework for integrating various astrophysical codes for solving 4 types of problems: gravitational dynamics, radiative transfer, hydrodynamics, and stellar evolution. The codes are written by the community and are interfaced together with Amuse. The user end is python. I have spent some time reading the book, which is instructive and well written. Steve McMillian is one of the authors. The code has a large support on GitHub and is still being developped. I have had trouble trying to install the code. It seems as though their documentation is incoherrent. At one place, it said `pip' is the easiest way to install. It didn't work. In another place, I was instructed to install a zipped up tarball. The setup failed becuase it expected there to be a .git file in the directory. I successfully downloaded the code by cloneing the repository, despite the fact that this was not recommended. I can use some aspects of the code but not all of them. For instance, my memory tells me that about 80\% of the test suite passed, thus many scripts failed. This was when I only installed the frame-work, which was advised since installing the whole package is huge and unnecessary since I am not solving all astrophysical problems. However, I wasn't able to use one of the gravity solvers that was presented in the textbook `AstrophysicalRecipes The art of AMUSE'. The install still has some codes that failed for instance: amuse-adaptb, amuse-hermite-grx, amuse-mi6. However, I'm hoping that this isn't necessary. I want to educate myself and make some examples. 

    Installing other codes and figuring out their functionalities to me has never been trivial. This is similar to galpy when I tried to figure out particle spray method and got less than good results. Agama also confused me a bit. The main point is that for each package, at the end of the day I decided that it was easier and better if I solved the problem myself with my own code. Because, even with the other packages, I know that they can be used to solve other astrophysical problems and it wasn't clear to me how to make the codes solve my specific set of of the restricted three body problems in a potential with other perturbers flying around. 

    In this search, I also discovered another review called \textit{Computational methods for collisional stellar systems} by Spurzem and Kamlah 2023. It is also interesting and instructive. I found it insightful when they called NBody an industry. I think the story of GRAPE and Makino is really interesting, how he build dedicated hardware for the nbody problem which were great for 10 years but were quickly replaced by GPU technology. 
    \begin{itemize}
        \item f2py, and why did we choose to use Fortran? 
        \item Bovy's guide for making a public python package
        \item migrating going from setuptools to meson
        \item a brief overview of how it works. 
        \item how I can either save orbits or snapshots
    \end{itemize}

    \section{Computation time and Data Volume}

    \begin{verbatim}
    VIDEO: cluster_showing_scale_and_dynamical_time.mp4
    \end{verbatim}
