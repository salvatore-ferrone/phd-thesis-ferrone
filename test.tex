\documentclass{article}
\usepackage{listings}
\usepackage{natbib}   % For citation management
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{config/psl-cover/aas_macros}
\geometry{a4paper,
  left= 3cm,right = 2cm,  
  top = 3cm,bottom = 3cm,
  headheight=6mm,         
  marginparwidth = 16mm}

\begin{document}
\section{Tstrippy}
    This project is built on \texttt{f2py}, based on the paradigm that code compiled in Fortran is significantly faster than Python, while Python, especially within Jupyter notebooks, is far more convenient for development and visualization. \texttt{f2py} stands for \textit{Fortran to Python} \citep{peterson2009f2py}. The name, \texttt{t-strip-py}, is short for \texttt{T}idal \texttt{Strip}ping \texttt{Py}thon. 

    \texttt{F2py} only supports \texttt{F77}/\texttt{F90}/\texttt{F95}. So we choose \texttt{F90} since it introduces \textit{modules}. A module is similar to an Object Oriented Programming. A Module has its own data, and subroutines that can modify said data. However, modules do not have ineritences, and there can not be more than one instantiation of a module, as there can be many instances of the same class within the same program. 

    \texttt{tstrippy} has five modules:
    \begin{itemize}
        \item \texttt{integrator}: the main module. This module stores the positions and velocities and computes the forces and time evolution of the orbits. It also writes out intermitten data during the simulations, if desired. It interfaces with the other modules within the code. 
        \item \texttt{potentials}: The analytical potentials that are used for the force computations. At the moment, it includes: \texttt{Plummer}, \texttt{Hernquist}, \texttt{AllenSantillian}, \texttt{MiyamotoNagai}, and \texttt{pouliasis2017pii}, which is a composition of other sub components. The user can also access this module directly in python if they are interested in, for example, computing the energy of a body in post production.
        \item \texttt{hostperturber}: this module stores the position of the host pertuber and  
        \item \texttt{perturbers}
        \item \texttt{galacticbar}
    \end{itemize}




    \subsection{Minimum example}
        If the package is properly installed on the system, it can be imported at the top of any Python script:
        \small
        \begin{lstlisting}[language=python]
            import tstrippy    
        \end{lstlisting}
        \normalsize
        Next, the user must load or define the initial conditions. The code provides:
        \begin{itemize}
            \item The masses, sizes, and kinematics of the globular cluster catalog from \citet{2018MNRAS.478.1520B};
            \item The galactic potential parameters for model II of \citet{2017A&A...598A..66P}; and
            \item A galactic reference frame.
        \end{itemize}

        \small
        \begin{lstlisting}[language=python]
            GCdata      = \
                tstrippy.Parsers.baumgardtMWGCs().data
            MWparams    = \
                tstrippy.Parsers.potential_parameters.pouliasis2017pii()
            MWrefframe  = \
                tstrippy.Parsers.potential_parameters.MWreferenceframe()
        \end{lstlisting}
        \normalsize
        The user must then select the system to integrate. For example, to integrate the orbits of observed globular clusters, one must convert the ICRS coordinates to a Galactocentric frame using \texttt{astropy} and the provided MW reference frame. Alternatively, to simulate a star cluster, one can generate a Plummer sphere:
        \small
        \begin{lstlisting}[language=python]
            xp,yp,zp,vxp,vyp,vzp=\
            tstrippy.ergodic.isotropicplummer(G,massHost,halfmassradius,NP)
        \end{lstlisting}
        Here, \texttt{NP} is the number of particles, \texttt{halfmassradius} is the system's half-mass radius, \texttt{massHost} is the total mass of the Plummer sphere, and \texttt{G} is the gravitational constant. All values must be in the same unit system.

        The integrator must then be initialized. All parameters are passed via lists that are unpacked at the function call. Here is an example of initializing the integrator for a stellar stream in a potential that includes a rotating galactic bar:
        \small
        \begin{lstlisting}[language=python]
            tstrippy.integrator.setstaticgalaxy(*staticgalaxy)
            tstrippy.integrator.setinitialkinematics(*initialkinematics)
            tstrippy.integrator.setintegrationparameters(*integrationparameters)
            tstrippy.integrator.inithostperturber(*hostperturber)
            tstrippy.integrator.initgalacticbar(*galacticbar)
            tstrippy.integrator.setbackwardorbit()
        \end{lstlisting}
        \normalsize

        \begin{itemize}
            \item \texttt{setstaticgalaxy} specifies the static potential model and passes its parameters.
            \item \texttt{setinitialkinematics} provides the initial positions and velocities of the particles.
            \item \texttt{setintegrationparameters} defines the initial time, timestep, and number of steps.
            \item \texttt{inithostperturber} specifies the globular cluster’s trajectory and mass as a function of time.
            \item \texttt{initgalacticbar} defines a rotating bar. It takes the name of the bar model, potential parameters, and spin parameters (polynomial coefficients for angular velocity):  
            \[
            \theta(t) = \theta_0 + \omega t + \dot{\omega} t^2 + \ddot{\omega} t^3 + \dots
            \]
            \item \texttt{setbackwardorbit} reverses the velocity vectors and sets the internal clock to count down: $t_i = t_0 - i \cdot \Delta t$. For the usecase presented in this work, \texttt{setbackwardorbit} is used for computing the globular cluster orbits and not for the star-particles. 
        \end{itemize}

        The user can choose between two output modes during integration:
        \begin{lstlisting}
            tstrippy.integrator.initwriteparticleorbits(nskip,myoutname,myoutdir)
            tstrippy.integrator.initwritestream(nskip,myoutname,myoutdir)
        \end{lstlisting}
        Conceptually, these represent two output paradigms:
        \begin{itemize}
            \item \texttt{initwriteparticleorbits} saves the full orbit of each particle to an individual file.
            \item \texttt{initwritestream} saves full snapshots of all particles at selected timesteps.
        \end{itemize}

        Both functions take:
        \begin{itemize}
            \item \texttt{nskip}: number of timesteps to skip between outputs;
            \item\texttt{myoutname}: the base file name;
            \item \texttt{myoutdir}: the output directory.
        \end{itemize}

        The output files will be named like: \texttt{../dir/temp0.bin}, \texttt{../dir/temp1.bin}, ..., up to \texttt{../dir/tempN.bin}, where $N = N_\mathrm{step} / N_\mathrm{skip}$. Note that the files are written in Fortran binary format. Although \texttt{scipy.io.FortranFile} can read them, I use a custom parser based on \texttt{numpy.frombuffer} to avoid the SciPy dependency.

        Once all parameters are set, the user can proceed with integration using one of two methods:

        \subsubsection*{Full orbit integration (in memory)}
        \small
        \begin{lstlisting}
            xt,yt,zt,vxt,vyt,vzt=\
                tstrippy.integrator.leapfrogintime(Ntimestep,nObj) 
            timestamps=\
                tstrippy.integrator.timestamps.copy()
        \end{lstlisting}
        \normalsize
        \texttt{leapfrogintime} stores the full orbit of each particle in memory. This is useful for a small number of particles or short integrations—e.g., rapid parameter studies in a notebook. However, for large simulations it can be prohibitively memory-intensive. For instance, integrating all globular clusters at high time resolution might require:
        \begin{equation}
            7 \times N_p \times N_\mathrm{step} \times 8~\mathrm{Byte} \approx 450~\mathrm{GB}
        \end{equation}
        if $N_\mathrm{step} \approx 10^7$. This will likely exceed system RAM.

        \subsubsection*{Final state only}
        \small
        \begin{lstlisting}
            tstrippy.integrator.leapfrogtofinalpositions()
            xf  = tstrippy.integrator.xf.copy()
            yf  = tstrippy.integrator.yf.copy()
            zf  = tstrippy.integrator.zf.copy()
            vxf = tstrippy.integrator.vxf.copy()
            vyf = tstrippy.integrator.vyf.copy()
            vzf = tstrippy.integrator.vzf.copy()
            finaltime=tstrippy.integrator.currenttime.copy()
        \end{lstlisting}
        \normalsize
        \texttt{leapfrogtofinalpositions()} performs the integration but only returns the final phase-space coordinates. These arrays must be copied before deallocating memory:
        \small
        \begin{lstlisting}
            tstrippy.integrator.deallocate()
        \end{lstlisting}
        \normalsize
        Deallocating is necessary to avoid memory leaks or crashes in Jupyter when rerunning code cells.



\bibliographystyle{plainnat}
\bibliography{mybib}

\end{document}



